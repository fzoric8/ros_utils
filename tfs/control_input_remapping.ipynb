{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9f389e56-f873-419f-ab32-b8281ea879db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a7d1e04-782b-4097-8468-19289c9a3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hp = np.matrix([[1, 2, 3], [5, 6, 7], [8, 9, 10], [11, 12, 13]]).T\n",
    "\n",
    "# Difference between point and vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e3aa2d2-648a-4921-be78-42b51eebbdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(Hp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85dec1af-6637-48ff-9245-b4e401018538",
   "metadata": {},
   "outputs": [],
   "source": [
    "O = np.matrix([[1, -1, 0, 0], \n",
    "              [0, 0, 1, -1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1347438a-72db-4d7a-a13c-c4df3e1702a9",
   "metadata": {},
   "source": [
    "# Dumb start\n",
    "\n",
    "Matrix $$\\mathbf{Hp} \\in \\mathbb{R}^{3\\times n_k}$$ contains 3D points of the human pose estimates. \n",
    "\n",
    "And it contains all points returned from the human pose estimation. \n",
    "\n",
    "We need to convert those points into control input signal. \n",
    "We do that with the help of matrix $$\\mathbf{O} \\in \\mathbb{R}^{n_k \\times n_u}$$. \n",
    "\n",
    "$$\\mathbf{\\hat{u}} = \\mathbf{H_P}\\mathbf{O}, \\quad \\mathbf{\\hat{u}} \\in \\mathbb{R}^{3 \\times n_u}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00fd2032-8794-4265-a554-4ed61d5a9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.matmul(Hp, O)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67cf05-881e-44b4-9443-17472f22a243",
   "metadata": {},
   "source": [
    "## Underactuated UAV control "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3e3a28-e889-4b0e-b461-59da661efd2e",
   "metadata": {},
   "source": [
    "For the case of the underactuated UAV control, we have two most common approaches. First approach is to control \n",
    "pose of the underactuated UAV, mainly x,y,z and yaw angle. \n",
    "\n",
    "And second one is to control roll, pitch, yaw and height directly. \n",
    "\n",
    "For the case scenario let's start with following assumption, we want to use generalized control input remapping to control position of the UAV with moving right arm further away from shoulder, and our left arm in elbow to increase height. \n",
    "\n",
    "#### Let's find wanted relationships \n",
    "\n",
    "Dict for the COCO annotations for human pose estimation is:\n",
    "\n",
    "```\n",
    "self.hpe_indexing = {0: \"nose\", 1: \"l_eye\", 2: \"r_eye\", 3: \"l_ear\", 4: \"r_ear\",\n",
    "                     5: \"l_shoulder\", 6: \"r_shoulder\", 7: \"l_elbow\", 8: \"r_elbow\",\n",
    "                     9: \"l_wrist\", 10: \"r_wrist\", 11: \"l_hip\", 12: \"r_hip\",\n",
    "                    13: \"l_knee\", 14: \"r_knee\", 15: \"l_ankle\", 16: \"r_ankle\", 17: \"background\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a231f21-b94f-4091-ae4a-7189c2a80ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hp = np.random.randint(-5, 5, (3, 18))\n",
    "O = np.zeros((18, 2))\n",
    "\n",
    "# r_shoulder [6] - r_wrist [10]\n",
    "# l_elbow [7] - l_wrist [9]\n",
    "O[6, 0] = 1\n",
    "O[10, 0] = -1\n",
    "O[7, 1] = 1\n",
    "O[9, 1] = -1\n",
    "\n",
    "# generalization \n",
    "nk = 18\n",
    "nu = 2\n",
    "Hp = np.random.randint(-5, 5, (3, nk))\n",
    "O = np.zeros((nk, nu))\n",
    "\n",
    "# All points are in essence vectors but from different origin etc...\n",
    "# vectors and points \n",
    "# Let's try this for starters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0138d575-a09b-4fb0-81df-911362b6d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_hat = np.matmul(Hp, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04705a8c-bcd7-4258-805a-c0f776768ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOmatrix(nu, nk, ap_ix, mp_ix):\n",
    "    \"\"\"\n",
    "        Create the O matrix for the input remapping.\n",
    "        Input: \n",
    "            nu: number of inputs\n",
    "            nk: number of keypoints\n",
    "            ap_ix: indices of anchor points\n",
    "            mp_ix: indices of mapping points\n",
    "        Output:\n",
    "            O: O matrix\n",
    "    \"\"\" \n",
    "    O = np.matrix(np.zeros((nu, nk)))\n",
    "    for i, a in enumerate(ap_ix):\n",
    "        O[a, i] = 1\n",
    "    for i, m in enumerate(mp_ix):\n",
    "        O[m, i] = -1\n",
    "    return O\n",
    "\n",
    "# It would make sense to think of normalization :) \n",
    "def createUmatrix(Hp, O): \n",
    "    u_hat = np.matmul(Hp, O)\n",
    "    return u_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c4235-0dbb-4ef0-93a7-5017fe2f8b7b",
   "metadata": {},
   "source": [
    "## Most common robots used\n",
    "\n",
    "### Robot manipulator \n",
    "\n",
    "There are multiple ways to control robot manipulator. \n",
    "First one is to control it in joint space, second one is to control it in the tool space. \n",
    "\n",
    "### Mobile robot \n",
    "\n",
    "#### UGV\n",
    "\n",
    "Most common method for controlling UGV is `cmd_vel`. \n",
    "\n",
    "#### UAV \n",
    "\n",
    "UAVs are controller through publishing pose (depends on the UAV), but more often than not, we control pose.  \n",
    "\n",
    "### Mobile manipulator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa6291-0d17-47ff-ae0c-70232944d29b",
   "metadata": {},
   "source": [
    "## Useful links: \n",
    "\n",
    "* [Normalizing a quasi-rotation matrix](https://math.stackexchange.com/questions/3292034/normalizing-a-quasi-rotation-matrix).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9058f0-0016-4efd-9ad1-84a6403fd7f1",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "- [ ] Check what physically means to sum/substract vectors (points)\n",
    "- [ ] Check what physically means to multiply/divide vectors (points)\n",
    "- [ ] Matrix multiplication?\n",
    "- [ ] Absolute vs. relative control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a9da3-7ff7-4fe6-b040-6faeb7d54f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
